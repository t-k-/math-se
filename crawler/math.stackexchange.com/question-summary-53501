X_1, ..., X_n
\frac 1 \lambda e^{-x / \lambda} I(x > 0).
h(\lambda) = e^{-\lambda}
P(X_1 > \lambda^2)
h(\lambda)
e^{-\bar X}
E[e^{-\bar X}] = M_{\bar X} (-1) = M_{X_1} \left(-\frac 1 n\right)^n = \left(1 + \frac \lambda n\right)^{-n}
M_Y
Y
g(\bar X)
E[g(\bar X)] = e^{-\lambda}
e^{-\lambda}
S=n\bar X_n
k\ge0
h(\lambda)=\mathrm{e}^{-\lambda}
H_n(\bar X_n)
 P_S(\mathrm{d}s)=\frac{s^{n-1}}{(n-1)!}\mathrm{e}^{-s/\lambda}\frac{\mathrm{d}s}{\lambda^n}. 
 E(S^k)=\frac{(n+k-1)!}{(n-1)!}\lambda^k. 
 \mathrm{e}^{-\lambda}=\sum_{k\ge0}(-1)^k\frac{\lambda^k}{k!}=\sum_{k\ge0}(-1)^k\frac{(n-1)!}{k!(n+k-1)!}E(S^k), 
 H_n(x)=(n-1)!\sum_{k\ge0}(-1)^k\frac{n^k}{k!(n+k-1)!}x^k={}_0F_1(-nx;n). 
e^{-\lambda} = \Pr(X_1 > 1)
Y
e^{-\lambda}
E(Y\mid X_1+\cdots+X_n) = \Pr(X_1>1 \mid X_1+\cdots+X_n)
 Y = \begin{cases}1 & \text{if }X_1> 1 \\ 0 & \text{otherwise}\end{cases} 
